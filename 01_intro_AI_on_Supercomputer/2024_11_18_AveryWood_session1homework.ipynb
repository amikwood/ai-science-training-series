{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "I ran into saving issues on the ALCF jupyter notebooks so I just moved everything to colab"
      ],
      "metadata": {
        "id": "sN_CBUO1IN1T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1BnqGXBEHqZe"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import IPython.display as ipydis\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! [ -e ./slimmed_realestate_data.csv ] || wget https://raw.githubusercontent.com/argonne-lcf/ai-science-training-series/main/01_intro_AI_on_Supercomputer/slimmed_realestate_data.csv\n",
        "data = pd.read_csv('slimmed_realestate_data.csv')\n",
        "print(data.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UbwW6AoHtAz",
        "outputId": "afc2e9fd-b9f0-4c9f-a2a6-9500713d20f9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-19 01:54:05--  https://raw.githubusercontent.com/argonne-lcf/ai-science-training-series/main/01_intro_AI_on_Supercomputer/slimmed_realestate_data.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8804 (8.6K) [text/plain]\n",
            "Saving to: ‘slimmed_realestate_data.csv’\n",
            "\n",
            "slimmed_realestate_ 100%[===================>]   8.60K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-11-19 01:54:06 (67.2 MB/s) - ‘slimmed_realestate_data.csv’ saved [8804/8804]\n",
            "\n",
            "Index(['Unnamed: 0', 'SalePrice', 'GrLivArea'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = len(data)\n",
        "x = data['GrLivArea'].to_numpy()\n",
        "y = data['SalePrice'].to_numpy()\n",
        "sum_xy = np.sum(x*y)\n",
        "sum_x = np.sum(x)\n",
        "sum_y = np.sum(y)\n",
        "sum_x2 = np.sum(x*x)\n",
        "denominator = n * sum_x2 - sum_x * sum_x\n",
        "m = (n * sum_xy - sum_x * sum_y) / denominator\n",
        "b = (sum_y * sum_x2 - sum_x * sum_xy) / denominator\n",
        "print('y = %f * x + %f' % (m,b))\n",
        "\n",
        "# saving these for later comparison\n",
        "m_calc = m\n",
        "b_calc = b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRnyYz7gHt_I",
        "outputId": "4aadecac-70ff-42be-841a-a8dbca52db0e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y = 87.688145 * x + 34754.077892\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_data(x,y,m,b,plt = plt):\n",
        "   # plot our data points with 'bo' = blue circles\n",
        "   plt.plot(x,y,'bo')\n",
        "   # create the line based on our linear fit\n",
        "   # first we need to make x points\n",
        "   # the 'arange' function generates points between two limits (min,max)\n",
        "   linear_x = np.arange(x.min(),x.max())\n",
        "   # now we use our fit parameters to calculate the y points based on our x points\n",
        "   linear_y = linear_x * m + b\n",
        "   # plot the linear points using 'r-' = red line\n",
        "   plt.plot(linear_x,linear_y,'r-',label='fit')\n",
        "\n",
        "def model(x,m,b):\n",
        "   return m * x + b\n",
        "\n",
        "def loss(x,y,m,b):\n",
        "   y_predicted = model(x,m,b)\n",
        "   return np.power( y - y_predicted, 2 )\n",
        "\n",
        "def updated_m(x,y,m,b,learning_rate):\n",
        "   dL_dm = - 2 * x * (y - model(x,m,b))\n",
        "   dL_dm = np.mean(dL_dm)\n",
        "   return m - learning_rate * dL_dm\n",
        "\n",
        "def updated_b(x,y,m,b,learning_rate):\n",
        "   dL_db = - 2 * (y - model(x,m,b))\n",
        "   dL_db = np.mean(dL_db)\n",
        "   return b - learning_rate * dL_db"
      ],
      "metadata": {
        "id": "NrKjk46ZHvSY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set our initial slope and intercept\n",
        "m = 5.\n",
        "b = 1000.\n",
        "# batch_size = 60\n",
        "# set a learning rate for each parameter\n",
        "learning_rate_m = 1e-7\n",
        "learning_rate_b = 1e-1\n",
        "# use these to plot our progress over time\n",
        "loss_history = []\n",
        "\n",
        "batch_size = 32\n",
        "# convert panda data to numpy arrays, one for the \"Ground Living Area\" and one for \"Sale Price\"\n",
        "#data_x = data['GrLivArea'].to_numpy()\n",
        "#data_y = data['SalePrice'].to_numpy()\n",
        "data_batch = data.sample(batch_size)\n",
        "data_x = data_batch['GrLivArea'].to_numpy()\n",
        "data_y = data_batch['SalePrice'].to_numpy()\n",
        "# we run our loop N times\n",
        "\n",
        "#loop_N = 30\n",
        "loop_N = 30*len(data)//batch_size\n",
        "\n",
        "for i in range(loop_N):\n",
        "   # update our slope and intercept based on the current values\n",
        "   m = updated_m(data_x,data_y,m,b,learning_rate_m)\n",
        "   b = updated_b(data_x,data_y,m,b,learning_rate_b)\n",
        "\n",
        "   # calculate the loss value\n",
        "   loss_value = np.mean(loss(data_x,data_y,m,b))\n",
        "\n",
        "   # keep a history of our loss values\n",
        "   loss_history.append(loss_value)\n",
        "\n",
        "      # print our progress\n",
        "   print('[%03d]  dy_i = %.2f * x + %.2f     previously calculated: y_i = %.2f * x + %.2f    loss: %f' % (i,m,b,m_calc,b_calc,loss_value))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZaU2mgvhH4gQ",
        "outputId": "a25d47b7-4186-4c99-fcf3-1fbca6de1ed7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[000]  dy_i = 63.19 * x + 15800.02     previously calculated: y_i = 87.69 * x + 34754.08    loss: 5328603331.515837\n",
            "[001]  dy_i = 83.36 * x + 21325.07     previously calculated: y_i = 87.69 * x + 34754.08    loss: 2153544353.584394\n",
            "[002]  dy_i = 90.22 * x + 23595.28     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1771024956.026054\n",
            "[003]  dy_i = 92.44 * x + 24717.74     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1724686689.672171\n",
            "[004]  dy_i = 93.03 * x + 25430.09     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1717613996.556343\n",
            "[005]  dy_i = 93.06 * x + 25990.71     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1714779138.102558\n",
            "[006]  dy_i = 92.90 * x + 26490.22     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1712344206.375268\n",
            "[007]  dy_i = 92.67 * x + 26960.55     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1709989506.803238\n",
            "[008]  dy_i = 92.43 * x + 27413.08     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1707723509.620868\n",
            "[009]  dy_i = 92.18 * x + 27851.98     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1705560030.424364\n",
            "[010]  dy_i = 91.94 * x + 28278.90     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1703501832.764188\n",
            "[011]  dy_i = 91.70 * x + 28694.60     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1701546501.520653\n",
            "[012]  dy_i = 91.47 * x + 29099.53     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1699689841.293501\n",
            "[013]  dy_i = 91.25 * x + 29494.03     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1697927198.089546\n",
            "[014]  dy_i = 91.03 * x + 29878.37     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1696253922.319810\n",
            "[015]  dy_i = 90.81 * x + 30252.84     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1694665520.946594\n",
            "[016]  dy_i = 90.60 * x + 30617.68     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1693157701.793420\n",
            "[017]  dy_i = 90.40 * x + 30973.15     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1691726381.207557\n",
            "[018]  dy_i = 90.20 * x + 31319.48     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1690367679.572405\n",
            "[019]  dy_i = 90.01 * x + 31656.91     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1689077913.033273\n",
            "[020]  dy_i = 89.82 * x + 31985.67     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1687853584.273714\n",
            "[021]  dy_i = 89.64 * x + 32305.99     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1686691373.292884\n",
            "[022]  dy_i = 89.46 * x + 32618.06     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1685588128.491606\n",
            "[023]  dy_i = 89.29 * x + 32922.12     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1684540858.156398\n",
            "[024]  dy_i = 89.12 * x + 33218.37     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1683546722.357044\n",
            "[025]  dy_i = 88.95 * x + 33507.00     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1682603025.248970\n",
            "[026]  dy_i = 88.79 * x + 33788.22     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1681707207.763980\n",
            "[027]  dy_i = 88.64 * x + 34062.21     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1680856840.671129\n",
            "[028]  dy_i = 88.48 * x + 34329.16     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1680049617.989399\n",
            "[029]  dy_i = 88.34 * x + 34589.24     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1679283350.734504\n",
            "[030]  dy_i = 88.19 * x + 34842.65     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1678555960.982941\n",
            "[031]  dy_i = 88.05 * x + 35089.54     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1677865476.237183\n",
            "[032]  dy_i = 87.91 * x + 35330.09     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1677210024.076771\n",
            "[033]  dy_i = 87.78 * x + 35564.45     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1676587827.080778\n",
            "[034]  dy_i = 87.65 * x + 35792.80     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1675997198.007897\n",
            "[035]  dy_i = 87.52 * x + 36015.27     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1675436535.221065\n",
            "[036]  dy_i = 87.40 * x + 36232.03     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1674904318.344225\n",
            "[037]  dy_i = 87.28 * x + 36443.22     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1674399104.139458\n",
            "[038]  dy_i = 87.16 * x + 36648.98     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1673919522.593277\n",
            "[039]  dy_i = 87.04 * x + 36849.45     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1673464273.201498\n",
            "[040]  dy_i = 86.93 * x + 37044.77     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1673032121.442605\n",
            "[041]  dy_i = 86.82 * x + 37235.07     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1672621895.430036\n",
            "[042]  dy_i = 86.72 * x + 37420.48     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1672232482.734321\n",
            "[043]  dy_i = 86.61 * x + 37601.13     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1671862827.366456\n",
            "[044]  dy_i = 86.51 * x + 37777.13     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1671511926.914327\n",
            "[045]  dy_i = 86.42 * x + 37948.61     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1671178829.824418\n",
            "[046]  dy_i = 86.32 * x + 38115.68     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1670862632.821445\n",
            "[047]  dy_i = 86.23 * x + 38278.46     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1670562478.458892\n",
            "[048]  dy_i = 86.14 * x + 38437.06     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1670277552.793843\n",
            "[049]  dy_i = 86.05 * x + 38591.58     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1670007083.179763\n",
            "[050]  dy_i = 85.96 * x + 38742.13     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1669750336.171282\n",
            "[051]  dy_i = 85.88 * x + 38888.82     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1669506615.535277\n",
            "[052]  dy_i = 85.80 * x + 39031.73     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1669275260.362858\n",
            "[053]  dy_i = 85.72 * x + 39170.97     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1669055643.277158\n",
            "[054]  dy_i = 85.64 * x + 39306.63     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1668847168.732036\n",
            "[055]  dy_i = 85.57 * x + 39438.80     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1668649271.397112\n",
            "[056]  dy_i = 85.49 * x + 39567.58     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1668461414.624731\n",
            "[057]  dy_i = 85.42 * x + 39693.05     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1668283088.994714\n",
            "[058]  dy_i = 85.35 * x + 39815.30     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1668113810.932932\n",
            "[059]  dy_i = 85.28 * x + 39934.40     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1667953121.399981\n",
            "[060]  dy_i = 85.22 * x + 40050.44     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1667800584.646381\n",
            "[061]  dy_i = 85.15 * x + 40163.50     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1667655787.030933\n",
            "[062]  dy_i = 85.09 * x + 40273.66     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1667518335.899027\n",
            "[063]  dy_i = 85.03 * x + 40380.98     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1667387858.517865\n",
            "[064]  dy_i = 84.97 * x + 40485.55     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1667264001.065701\n",
            "[065]  dy_i = 84.91 * x + 40587.43     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1667146427.672368\n",
            "[066]  dy_i = 84.85 * x + 40686.69     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1667034819.508478\n",
            "[067]  dy_i = 84.80 * x + 40783.40     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1666928873.920846\n",
            "[068]  dy_i = 84.74 * x + 40877.62     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1666828303.611759\n",
            "[069]  dy_i = 84.69 * x + 40969.43     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1666732835.859910\n",
            "[070]  dy_i = 84.64 * x + 41058.87     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1666642211.780835\n",
            "[071]  dy_i = 84.59 * x + 41146.02     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1666556185.624892\n",
            "[072]  dy_i = 84.54 * x + 41230.92     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1666474524.110845\n",
            "[073]  dy_i = 84.49 * x + 41313.65     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1666397005.793267\n",
            "[074]  dy_i = 84.45 * x + 41394.24     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1666323420.462034\n",
            "[075]  dy_i = 84.40 * x + 41472.77     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1666253568.572289\n",
            "[076]  dy_i = 84.36 * x + 41549.28     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1666187260.703326\n",
            "[077]  dy_i = 84.32 * x + 41623.82     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1666124317.044931\n",
            "[078]  dy_i = 84.28 * x + 41696.45     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1666064566.909780\n",
            "[079]  dy_i = 84.23 * x + 41767.21     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1666007848.270576\n",
            "[080]  dy_i = 84.20 * x + 41836.15     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1665954007.320678\n",
            "[081]  dy_i = 84.16 * x + 41903.32     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1665902898.057011\n",
            "[082]  dy_i = 84.12 * x + 41968.77     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1665854381.884143\n",
            "[083]  dy_i = 84.08 * x + 42032.53     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1665808327.238452\n",
            "[084]  dy_i = 84.05 * x + 42094.65     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1665764609.231355\n",
            "[085]  dy_i = 84.01 * x + 42155.18     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1665723109.310645\n",
            "[086]  dy_i = 83.98 * x + 42214.15     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1665683714.939004\n",
            "[087]  dy_i = 83.95 * x + 42271.61     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1665646319.288835\n",
            "[088]  dy_i = 83.91 * x + 42327.59     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1665610820.952566\n",
            "[089]  dy_i = 83.88 * x + 42382.13     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1665577123.667663\n",
            "[090]  dy_i = 83.85 * x + 42435.27     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1665545136.055590\n",
            "[091]  dy_i = 83.82 * x + 42487.05     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1665514771.374012\n",
            "[092]  dy_i = 83.79 * x + 42537.49     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1665485947.281571\n",
            "[093]  dy_i = 83.77 * x + 42586.64     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1665458585.614600\n",
            "[094]  dy_i = 83.74 * x + 42634.52     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1665432612.175159\n",
            "[095]  dy_i = 83.71 * x + 42681.18     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1665407956.529832\n",
            "[096]  dy_i = 83.69 * x + 42726.63     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1665384551.818728\n",
            "[097]  dy_i = 83.66 * x + 42770.92     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1665362334.574176\n",
            "[098]  dy_i = 83.64 * x + 42814.07     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1665341244.548610\n",
            "[099]  dy_i = 83.61 * x + 42856.11     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1665321224.551203\n",
            "[100]  dy_i = 83.59 * x + 42897.07     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1665302220.292771\n",
            "[101]  dy_i = 83.57 * x + 42936.97     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1665284180.238557\n",
            "[102]  dy_i = 83.54 * x + 42975.86     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1665267055.468488\n",
            "[103]  dy_i = 83.52 * x + 43013.74     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1665250799.544504\n",
            "[104]  dy_i = 83.50 * x + 43050.65     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1665235368.384641\n",
            "[105]  dy_i = 83.48 * x + 43086.61     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1665220720.143486\n",
            "[106]  dy_i = 83.46 * x + 43121.64     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1665206815.098703\n",
            "[107]  dy_i = 83.44 * x + 43155.78     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1665193615.543320\n",
            "[108]  dy_i = 83.42 * x + 43189.04     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1665181085.683470\n",
            "[109]  dy_i = 83.40 * x + 43221.44     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1665169191.541336\n",
            "[110]  dy_i = 83.39 * x + 43253.01     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1665157900.863002\n",
            "[111]  dy_i = 83.37 * x + 43283.77     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1665147183.030998\n",
            "[112]  dy_i = 83.35 * x + 43313.74     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1665137008.981267\n",
            "[113]  dy_i = 83.33 * x + 43342.94     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1665127351.124352\n",
            "[114]  dy_i = 83.32 * x + 43371.39     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1665118183.270581\n",
            "[115]  dy_i = 83.30 * x + 43399.11     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1665109480.559049\n",
            "[116]  dy_i = 83.29 * x + 43426.11     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1665101219.390195\n",
            "[117]  dy_i = 83.27 * x + 43452.42     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1665093377.361814\n",
            "[118]  dy_i = 83.26 * x + 43478.06     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1665085933.208303\n",
            "[119]  dy_i = 83.24 * x + 43503.03     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1665078866.742996\n",
            "[120]  dy_i = 83.23 * x + 43527.37     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1665072158.803421\n",
            "[121]  dy_i = 83.22 * x + 43551.08     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1665065791.199339\n",
            "[122]  dy_i = 83.20 * x + 43574.18     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1665059746.663411\n",
            "[123]  dy_i = 83.19 * x + 43596.69     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1665054008.804384\n",
            "[124]  dy_i = 83.18 * x + 43618.61     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1665048562.062628\n",
            "[125]  dy_i = 83.16 * x + 43639.98     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1665043391.667956\n",
            "[126]  dy_i = 83.15 * x + 43660.79     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1665038483.599561\n",
            "[127]  dy_i = 83.14 * x + 43681.07     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1665033824.547999\n",
            "[128]  dy_i = 83.13 * x + 43700.83     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1665029401.879099\n",
            "[129]  dy_i = 83.12 * x + 43720.08     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1665025203.599696\n",
            "[130]  dy_i = 83.11 * x + 43738.84     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1665021218.325117\n",
            "[131]  dy_i = 83.10 * x + 43757.12     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1665017435.248302\n",
            "[132]  dy_i = 83.09 * x + 43774.92     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1665013844.110502\n",
            "[133]  dy_i = 83.08 * x + 43792.27     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1665010435.173455\n",
            "[134]  dy_i = 83.07 * x + 43809.17     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1665007199.192986\n",
            "[135]  dy_i = 83.06 * x + 43825.64     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1665004127.393930\n",
            "[136]  dy_i = 83.05 * x + 43841.68     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1665001211.446345\n",
            "[137]  dy_i = 83.04 * x + 43857.31     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664998443.442915\n",
            "[138]  dy_i = 83.03 * x + 43872.54     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664995815.877514\n",
            "[139]  dy_i = 83.02 * x + 43887.38     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664993321.624846\n",
            "[140]  dy_i = 83.02 * x + 43901.84     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664990953.921129\n",
            "[141]  dy_i = 83.01 * x + 43915.93     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664988706.345746\n",
            "[142]  dy_i = 83.00 * x + 43929.65     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664986572.803839\n",
            "[143]  dy_i = 82.99 * x + 43943.02     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664984547.509783\n",
            "[144]  dy_i = 82.98 * x + 43956.05     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664982624.971490\n",
            "[145]  dy_i = 82.98 * x + 43968.74     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664980799.975520\n",
            "[146]  dy_i = 82.97 * x + 43981.11     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664979067.572947\n",
            "[147]  dy_i = 82.96 * x + 43993.16     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664977423.065929\n",
            "[148]  dy_i = 82.96 * x + 44004.90     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664975861.994980\n",
            "[149]  dy_i = 82.95 * x + 44016.34     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664974380.126868\n",
            "[150]  dy_i = 82.94 * x + 44027.48     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664972973.443142\n",
            "[151]  dy_i = 82.94 * x + 44038.34     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664971638.129230\n",
            "[152]  dy_i = 82.93 * x + 44048.91     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664970370.564097\n",
            "[153]  dy_i = 82.93 * x + 44059.22     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664969167.310426\n",
            "[154]  dy_i = 82.92 * x + 44069.26     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664968025.105297\n",
            "[155]  dy_i = 82.91 * x + 44079.05     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664966940.851337\n",
            "[156]  dy_i = 82.91 * x + 44088.58     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664965911.608325\n",
            "[157]  dy_i = 82.90 * x + 44097.87     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664964934.585211\n",
            "[158]  dy_i = 82.90 * x + 44106.91     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664964007.132556\n",
            "[159]  dy_i = 82.89 * x + 44115.73     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664963126.735342\n",
            "[160]  dy_i = 82.89 * x + 44124.32     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664962291.006154\n",
            "[161]  dy_i = 82.88 * x + 44132.69     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664961497.678705\n",
            "[162]  dy_i = 82.88 * x + 44140.84     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664960744.601691\n",
            "[163]  dy_i = 82.87 * x + 44148.79     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664960029.732958\n",
            "[164]  dy_i = 82.87 * x + 44156.53     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664959351.133961\n",
            "[165]  dy_i = 82.87 * x + 44164.07     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664958706.964512\n",
            "[166]  dy_i = 82.86 * x + 44171.41     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664958095.477785\n",
            "[167]  dy_i = 82.86 * x + 44178.57     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664957515.015583\n",
            "[168]  dy_i = 82.85 * x + 44185.55     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664956964.003838\n",
            "[169]  dy_i = 82.85 * x + 44192.34     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664956440.948346\n",
            "[170]  dy_i = 82.85 * x + 44198.96     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664955944.430712\n",
            "[171]  dy_i = 82.84 * x + 44205.41     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664955473.104505\n",
            "[172]  dy_i = 82.84 * x + 44211.70     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664955025.691608\n",
            "[173]  dy_i = 82.83 * x + 44217.82     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664954600.978749\n",
            "[174]  dy_i = 82.83 * x + 44223.79     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664954197.814215\n",
            "[175]  dy_i = 82.83 * x + 44229.60     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664953815.104727\n",
            "[176]  dy_i = 82.82 * x + 44235.26     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664953451.812469\n",
            "[177]  dy_i = 82.82 * x + 44240.78     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664953106.952288\n",
            "[178]  dy_i = 82.82 * x + 44246.16     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664952779.589008\n",
            "[179]  dy_i = 82.82 * x + 44251.39     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664952468.834904\n",
            "[180]  dy_i = 82.81 * x + 44256.50     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664952173.847287\n",
            "[181]  dy_i = 82.81 * x + 44261.47     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664951893.826227\n",
            "[182]  dy_i = 82.81 * x + 44266.31     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664951628.012377\n",
            "[183]  dy_i = 82.80 * x + 44271.03     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664951375.684917\n",
            "[184]  dy_i = 82.80 * x + 44275.63     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664951136.159598\n",
            "[185]  dy_i = 82.80 * x + 44280.11     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664950908.786888\n",
            "[186]  dy_i = 82.80 * x + 44284.48     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664950692.950209\n",
            "[187]  dy_i = 82.79 * x + 44288.73     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664950488.064268\n",
            "[188]  dy_i = 82.79 * x + 44292.87     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664950293.573465\n",
            "[189]  dy_i = 82.79 * x + 44296.91     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664950108.950390\n",
            "[190]  dy_i = 82.79 * x + 44300.84     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664949933.694391\n",
            "[191]  dy_i = 82.79 * x + 44304.67     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664949767.330219\n",
            "[192]  dy_i = 82.78 * x + 44308.41     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664949609.406736\n",
            "[193]  dy_i = 82.78 * x + 44312.05     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664949459.495694\n",
            "[194]  dy_i = 82.78 * x + 44315.59     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664949317.190571\n",
            "[195]  dy_i = 82.78 * x + 44319.04     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664949182.105472\n",
            "[196]  dy_i = 82.77 * x + 44322.41     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664949053.874080\n",
            "[197]  dy_i = 82.77 * x + 44325.69     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664948932.148664\n",
            "[198]  dy_i = 82.77 * x + 44328.88     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664948816.599136\n",
            "[199]  dy_i = 82.77 * x + 44331.99     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664948706.912154\n",
            "[200]  dy_i = 82.77 * x + 44335.02     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664948602.790275\n",
            "[201]  dy_i = 82.77 * x + 44337.98     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664948503.951146\n",
            "[202]  dy_i = 82.76 * x + 44340.86     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664948410.126740\n",
            "[203]  dy_i = 82.76 * x + 44343.66     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664948321.062631\n",
            "[204]  dy_i = 82.76 * x + 44346.39     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664948236.517297\n",
            "[205]  dy_i = 82.76 * x + 44349.05     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664948156.261475\n",
            "[206]  dy_i = 82.76 * x + 44351.65     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664948080.077528\n",
            "[207]  dy_i = 82.76 * x + 44354.17     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664948007.758868\n",
            "[208]  dy_i = 82.76 * x + 44356.64     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664947939.109383\n",
            "[209]  dy_i = 82.75 * x + 44359.03     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664947873.942913\n",
            "[210]  dy_i = 82.75 * x + 44361.37     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664947812.082744\n",
            "[211]  dy_i = 82.75 * x + 44363.65     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664947753.361125\n",
            "[212]  dy_i = 82.75 * x + 44365.87     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664947697.618819\n",
            "[213]  dy_i = 82.75 * x + 44368.03     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664947644.704668\n",
            "[214]  dy_i = 82.75 * x + 44370.13     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664947594.475180\n",
            "[215]  dy_i = 82.75 * x + 44372.18     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664947546.794147\n",
            "[216]  dy_i = 82.75 * x + 44374.18     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664947501.532269\n",
            "[217]  dy_i = 82.74 * x + 44376.13     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664947458.566808\n",
            "[218]  dy_i = 82.74 * x + 44378.03     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664947417.781251\n",
            "[219]  dy_i = 82.74 * x + 44379.88     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664947379.065000\n",
            "[220]  dy_i = 82.74 * x + 44381.68     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664947342.313064\n",
            "[221]  dy_i = 82.74 * x + 44383.43     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664947307.425783\n",
            "[222]  dy_i = 82.74 * x + 44385.14     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664947274.308551\n",
            "[223]  dy_i = 82.74 * x + 44386.81     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664947242.871562\n",
            "[224]  dy_i = 82.74 * x + 44388.43     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664947213.029566\n",
            "[225]  dy_i = 82.74 * x + 44390.01     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664947184.701641\n",
            "[226]  dy_i = 82.74 * x + 44391.55     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664947157.810968\n",
            "[227]  dy_i = 82.73 * x + 44393.06     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664947132.284626\n",
            "[228]  dy_i = 82.73 * x + 44394.52     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664947108.053394\n",
            "[229]  dy_i = 82.73 * x + 44395.94     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664947085.051562\n",
            "[230]  dy_i = 82.73 * x + 44397.33     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664947063.216757\n",
            "[231]  dy_i = 82.73 * x + 44398.68     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664947042.489768\n",
            "[232]  dy_i = 82.73 * x + 44400.00     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664947022.814387\n",
            "[233]  dy_i = 82.73 * x + 44401.29     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664947004.137261\n",
            "[234]  dy_i = 82.73 * x + 44402.54     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946986.407742\n",
            "[235]  dy_i = 82.73 * x + 44403.76     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946969.577751\n",
            "[236]  dy_i = 82.73 * x + 44404.94     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946953.601650\n",
            "[237]  dy_i = 82.73 * x + 44406.10     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946938.436117\n",
            "[238]  dy_i = 82.73 * x + 44407.23     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946924.040025\n",
            "[239]  dy_i = 82.73 * x + 44408.33     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946910.374337\n",
            "[240]  dy_i = 82.73 * x + 44409.40     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946897.401994\n",
            "[241]  dy_i = 82.72 * x + 44410.44     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946885.087818\n",
            "[242]  dy_i = 82.72 * x + 44411.46     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946873.398417\n",
            "[243]  dy_i = 82.72 * x + 44412.45     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946862.302093\n",
            "[244]  dy_i = 82.72 * x + 44413.41     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946851.768753\n",
            "[245]  dy_i = 82.72 * x + 44414.35     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946841.769836\n",
            "[246]  dy_i = 82.72 * x + 44415.26     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946832.278226\n",
            "[247]  dy_i = 82.72 * x + 44416.16     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946823.268184\n",
            "[248]  dy_i = 82.72 * x + 44417.03     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946814.715278\n",
            "[249]  dy_i = 82.72 * x + 44417.87     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946806.596314\n",
            "[250]  dy_i = 82.72 * x + 44418.70     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946798.889275\n",
            "[251]  dy_i = 82.72 * x + 44419.50     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946791.573262\n",
            "[252]  dy_i = 82.72 * x + 44420.28     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946784.628437\n",
            "[253]  dy_i = 82.72 * x + 44421.05     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946778.035965\n",
            "[254]  dy_i = 82.72 * x + 44421.79     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946771.777970\n",
            "[255]  dy_i = 82.72 * x + 44422.51     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946765.837483\n",
            "[256]  dy_i = 82.72 * x + 44423.22     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946760.198393\n",
            "[257]  dy_i = 82.72 * x + 44423.91     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946754.845410\n",
            "[258]  dy_i = 82.72 * x + 44424.58     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946749.764017\n",
            "[259]  dy_i = 82.72 * x + 44425.23     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946744.940434\n",
            "[260]  dy_i = 82.72 * x + 44425.86     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946740.361581\n",
            "[261]  dy_i = 82.72 * x + 44426.48     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946736.015042\n",
            "[262]  dy_i = 82.72 * x + 44427.09     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946731.889031\n",
            "[263]  dy_i = 82.71 * x + 44427.68     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946727.972358\n",
            "[264]  dy_i = 82.71 * x + 44428.25     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946724.254401\n",
            "[265]  dy_i = 82.71 * x + 44428.81     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946720.725080\n",
            "[266]  dy_i = 82.71 * x + 44429.35     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946717.374823\n",
            "[267]  dy_i = 82.71 * x + 44429.88     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946714.194546\n",
            "[268]  dy_i = 82.71 * x + 44430.40     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946711.175623\n",
            "[269]  dy_i = 82.71 * x + 44430.90     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946708.309869\n",
            "[270]  dy_i = 82.71 * x + 44431.39     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946705.589514\n",
            "[271]  dy_i = 82.71 * x + 44431.87     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946703.007178\n",
            "[272]  dy_i = 82.71 * x + 44432.33     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946700.555861\n",
            "[273]  dy_i = 82.71 * x + 44432.79     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946698.228914\n",
            "[274]  dy_i = 82.71 * x + 44433.23     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946696.020027\n",
            "[275]  dy_i = 82.71 * x + 44433.66     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946693.923211\n",
            "[276]  dy_i = 82.71 * x + 44434.08     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946691.932780\n",
            "[277]  dy_i = 82.71 * x + 44434.49     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946690.043336\n",
            "[278]  dy_i = 82.71 * x + 44434.88     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946688.249754\n",
            "[279]  dy_i = 82.71 * x + 44435.27     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946686.547173\n",
            "[280]  dy_i = 82.71 * x + 44435.65     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946684.930974\n",
            "[281]  dy_i = 82.71 * x + 44436.02     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946683.396774\n",
            "[282]  dy_i = 82.71 * x + 44436.38     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946681.940415\n",
            "[283]  dy_i = 82.71 * x + 44436.72     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946680.557945\n",
            "[284]  dy_i = 82.71 * x + 44437.06     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946679.245617\n",
            "[285]  dy_i = 82.71 * x + 44437.40     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946677.999871\n",
            "[286]  dy_i = 82.71 * x + 44437.72     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946676.817330\n",
            "[287]  dy_i = 82.71 * x + 44438.03     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946675.694786\n",
            "[288]  dy_i = 82.71 * x + 44438.34     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946674.629196\n",
            "[289]  dy_i = 82.71 * x + 44438.64     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946673.617670\n",
            "[290]  dy_i = 82.71 * x + 44438.93     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946672.657465\n",
            "[291]  dy_i = 82.71 * x + 44439.21     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946671.745977\n",
            "[292]  dy_i = 82.71 * x + 44439.49     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946670.880734\n",
            "[293]  dy_i = 82.71 * x + 44439.76     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946670.059391\n",
            "[294]  dy_i = 82.71 * x + 44440.02     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946669.279720\n",
            "[295]  dy_i = 82.71 * x + 44440.28     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946668.539606\n",
            "[296]  dy_i = 82.71 * x + 44440.53     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946667.837042\n",
            "[297]  dy_i = 82.71 * x + 44440.77     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946667.170125\n",
            "[298]  dy_i = 82.71 * x + 44441.01     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946666.537044\n",
            "[299]  dy_i = 82.71 * x + 44441.24     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946665.936084\n",
            "[300]  dy_i = 82.71 * x + 44441.46     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946665.365613\n",
            "[301]  dy_i = 82.71 * x + 44441.68     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946664.824086\n",
            "[302]  dy_i = 82.71 * x + 44441.89     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946664.310034\n",
            "[303]  dy_i = 82.71 * x + 44442.10     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946663.822064\n",
            "[304]  dy_i = 82.71 * x + 44442.30     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946663.358851\n",
            "[305]  dy_i = 82.71 * x + 44442.50     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946662.919139\n",
            "[306]  dy_i = 82.71 * x + 44442.69     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946662.501737\n",
            "[307]  dy_i = 82.71 * x + 44442.88     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946662.105513\n",
            "[308]  dy_i = 82.71 * x + 44443.06     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946661.729391\n",
            "[309]  dy_i = 82.71 * x + 44443.24     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946661.372352\n",
            "[310]  dy_i = 82.71 * x + 44443.41     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946661.033428\n",
            "[311]  dy_i = 82.71 * x + 44443.58     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946660.711700\n",
            "[312]  dy_i = 82.71 * x + 44443.74     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946660.406295\n",
            "[313]  dy_i = 82.71 * x + 44443.90     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946660.116385\n",
            "[314]  dy_i = 82.71 * x + 44444.06     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946659.841185\n",
            "[315]  dy_i = 82.71 * x + 44444.21     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946659.579947\n",
            "[316]  dy_i = 82.71 * x + 44444.36     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946659.331963\n",
            "[317]  dy_i = 82.71 * x + 44444.50     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946659.096560\n",
            "[318]  dy_i = 82.71 * x + 44444.64     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946658.873102\n",
            "[319]  dy_i = 82.71 * x + 44444.78     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946658.660980\n",
            "[320]  dy_i = 82.70 * x + 44444.91     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946658.459620\n",
            "[321]  dy_i = 82.70 * x + 44445.04     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946658.268478\n",
            "[322]  dy_i = 82.70 * x + 44445.17     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946658.087033\n",
            "[323]  dy_i = 82.70 * x + 44445.29     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946657.914794\n",
            "[324]  dy_i = 82.70 * x + 44445.41     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946657.751293\n",
            "[325]  dy_i = 82.70 * x + 44445.53     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946657.596088\n",
            "[326]  dy_i = 82.70 * x + 44445.65     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946657.448758\n",
            "[327]  dy_i = 82.70 * x + 44445.76     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946657.308903\n",
            "[328]  dy_i = 82.70 * x + 44445.86     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946657.176143\n",
            "[329]  dy_i = 82.70 * x + 44445.97     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946657.050118\n",
            "[330]  dy_i = 82.70 * x + 44446.07     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946656.930489\n",
            "[331]  dy_i = 82.70 * x + 44446.17     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946656.816928\n",
            "[332]  dy_i = 82.70 * x + 44446.27     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946656.709129\n",
            "[333]  dy_i = 82.70 * x + 44446.37     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946656.606799\n",
            "[334]  dy_i = 82.70 * x + 44446.46     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946656.509662\n",
            "[335]  dy_i = 82.70 * x + 44446.55     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946656.417452\n",
            "[336]  dy_i = 82.70 * x + 44446.64     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946656.329921\n",
            "[337]  dy_i = 82.70 * x + 44446.72     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946656.246831\n",
            "[338]  dy_i = 82.70 * x + 44446.81     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946656.167957\n",
            "[339]  dy_i = 82.70 * x + 44446.89     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946656.093085\n",
            "[340]  dy_i = 82.70 * x + 44446.97     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946656.022011\n",
            "[341]  dy_i = 82.70 * x + 44447.04     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946655.954543\n",
            "[342]  dy_i = 82.70 * x + 44447.12     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946655.890498\n",
            "[343]  dy_i = 82.70 * x + 44447.19     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946655.829703\n",
            "[344]  dy_i = 82.70 * x + 44447.26     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946655.771992\n",
            "[345]  dy_i = 82.70 * x + 44447.33     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946655.717209\n",
            "[346]  dy_i = 82.70 * x + 44447.40     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946655.665206\n",
            "[347]  dy_i = 82.70 * x + 44447.47     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946655.615841\n",
            "[348]  dy_i = 82.70 * x + 44447.53     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946655.568981\n",
            "[349]  dy_i = 82.70 * x + 44447.59     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946655.524498\n",
            "[350]  dy_i = 82.70 * x + 44447.65     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946655.482272\n",
            "[351]  dy_i = 82.70 * x + 44447.71     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946655.442189\n",
            "[352]  dy_i = 82.70 * x + 44447.77     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946655.404139\n",
            "[353]  dy_i = 82.70 * x + 44447.83     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946655.368020\n",
            "[354]  dy_i = 82.70 * x + 44447.88     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946655.333733\n",
            "[355]  dy_i = 82.70 * x + 44447.94     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946655.301186\n",
            "[356]  dy_i = 82.70 * x + 44447.99     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946655.270290\n",
            "[357]  dy_i = 82.70 * x + 44448.04     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946655.240962\n",
            "[358]  dy_i = 82.70 * x + 44448.09     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946655.213121\n",
            "[359]  dy_i = 82.70 * x + 44448.14     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946655.186694\n",
            "[360]  dy_i = 82.70 * x + 44448.19     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946655.161607\n",
            "[361]  dy_i = 82.70 * x + 44448.23     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946655.137793\n",
            "[362]  dy_i = 82.70 * x + 44448.28     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946655.115186\n",
            "[363]  dy_i = 82.70 * x + 44448.32     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946655.093728\n",
            "[364]  dy_i = 82.70 * x + 44448.36     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946655.073358\n",
            "[365]  dy_i = 82.70 * x + 44448.40     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946655.054020\n",
            "[366]  dy_i = 82.70 * x + 44448.44     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946655.035665\n",
            "[367]  dy_i = 82.70 * x + 44448.48     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946655.018241\n",
            "[368]  dy_i = 82.70 * x + 44448.52     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946655.001700\n",
            "[369]  dy_i = 82.70 * x + 44448.56     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.985999\n",
            "[370]  dy_i = 82.70 * x + 44448.59     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.971095\n",
            "[371]  dy_i = 82.70 * x + 44448.63     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.956947\n",
            "[372]  dy_i = 82.70 * x + 44448.66     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.943516\n",
            "[373]  dy_i = 82.70 * x + 44448.70     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.930767\n",
            "[374]  dy_i = 82.70 * x + 44448.73     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.918665\n",
            "[375]  dy_i = 82.70 * x + 44448.76     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.907177\n",
            "[376]  dy_i = 82.70 * x + 44448.79     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.896272\n",
            "[377]  dy_i = 82.70 * x + 44448.82     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.885919\n",
            "[378]  dy_i = 82.70 * x + 44448.85     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.876092\n",
            "[379]  dy_i = 82.70 * x + 44448.88     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.866765\n",
            "[380]  dy_i = 82.70 * x + 44448.91     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.857909\n",
            "[381]  dy_i = 82.70 * x + 44448.94     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.849504\n",
            "[382]  dy_i = 82.70 * x + 44448.96     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.841525\n",
            "[383]  dy_i = 82.70 * x + 44448.99     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.833950\n",
            "[384]  dy_i = 82.70 * x + 44449.01     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.826760\n",
            "[385]  dy_i = 82.70 * x + 44449.04     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.819935\n",
            "[386]  dy_i = 82.70 * x + 44449.06     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.813456\n",
            "[387]  dy_i = 82.70 * x + 44449.09     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.807305\n",
            "[388]  dy_i = 82.70 * x + 44449.11     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.801467\n",
            "[389]  dy_i = 82.70 * x + 44449.13     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.795926\n",
            "[390]  dy_i = 82.70 * x + 44449.15     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.790664\n",
            "[391]  dy_i = 82.70 * x + 44449.17     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.785671\n",
            "[392]  dy_i = 82.70 * x + 44449.19     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.780930\n",
            "[393]  dy_i = 82.70 * x + 44449.21     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.776430\n",
            "[394]  dy_i = 82.70 * x + 44449.23     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.772158\n",
            "[395]  dy_i = 82.70 * x + 44449.25     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.768103\n",
            "[396]  dy_i = 82.70 * x + 44449.27     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.764254\n",
            "[397]  dy_i = 82.70 * x + 44449.29     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.760600\n",
            "[398]  dy_i = 82.70 * x + 44449.31     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.757132\n",
            "[399]  dy_i = 82.70 * x + 44449.32     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.753839\n",
            "[400]  dy_i = 82.70 * x + 44449.34     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.750713\n",
            "[401]  dy_i = 82.70 * x + 44449.36     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.747746\n",
            "[402]  dy_i = 82.70 * x + 44449.37     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.744930\n",
            "[403]  dy_i = 82.70 * x + 44449.39     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.742257\n",
            "[404]  dy_i = 82.70 * x + 44449.40     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.739719\n",
            "[405]  dy_i = 82.70 * x + 44449.42     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.737309\n",
            "[406]  dy_i = 82.70 * x + 44449.43     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.735023\n",
            "[407]  dy_i = 82.70 * x + 44449.44     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.732852\n",
            "[408]  dy_i = 82.70 * x + 44449.46     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.730791\n",
            "[409]  dy_i = 82.70 * x + 44449.47     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.728835\n",
            "[410]  dy_i = 82.70 * x + 44449.48     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.726978\n",
            "[411]  dy_i = 82.70 * x + 44449.50     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.725215\n",
            "[412]  dy_i = 82.70 * x + 44449.51     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.723542\n",
            "[413]  dy_i = 82.70 * x + 44449.52     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.721954\n",
            "[414]  dy_i = 82.70 * x + 44449.53     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.720445\n",
            "[415]  dy_i = 82.70 * x + 44449.54     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.719015\n",
            "[416]  dy_i = 82.70 * x + 44449.55     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.717656\n",
            "[417]  dy_i = 82.70 * x + 44449.56     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.716366\n",
            "[418]  dy_i = 82.70 * x + 44449.58     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.715141\n",
            "[419]  dy_i = 82.70 * x + 44449.59     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.713980\n",
            "[420]  dy_i = 82.70 * x + 44449.60     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.712876\n",
            "[421]  dy_i = 82.70 * x + 44449.60     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.711829\n",
            "[422]  dy_i = 82.70 * x + 44449.61     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.710835\n",
            "[423]  dy_i = 82.70 * x + 44449.62     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.709891\n",
            "[424]  dy_i = 82.70 * x + 44449.63     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.708995\n",
            "[425]  dy_i = 82.70 * x + 44449.64     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.708145\n",
            "[426]  dy_i = 82.70 * x + 44449.65     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.707338\n",
            "[427]  dy_i = 82.70 * x + 44449.66     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.706572\n",
            "[428]  dy_i = 82.70 * x + 44449.67     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.705845\n",
            "[429]  dy_i = 82.70 * x + 44449.67     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.705153\n",
            "[430]  dy_i = 82.70 * x + 44449.68     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.704499\n",
            "[431]  dy_i = 82.70 * x + 44449.69     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.703876\n",
            "[432]  dy_i = 82.70 * x + 44449.70     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.703286\n",
            "[433]  dy_i = 82.70 * x + 44449.70     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.702725\n",
            "[434]  dy_i = 82.70 * x + 44449.71     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.702192\n",
            "[435]  dy_i = 82.70 * x + 44449.72     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.701688\n",
            "[436]  dy_i = 82.70 * x + 44449.72     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.701208\n",
            "[437]  dy_i = 82.70 * x + 44449.73     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.700753\n",
            "[438]  dy_i = 82.70 * x + 44449.74     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.700321\n",
            "[439]  dy_i = 82.70 * x + 44449.74     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.699910\n",
            "[440]  dy_i = 82.70 * x + 44449.75     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.699521\n",
            "[441]  dy_i = 82.70 * x + 44449.75     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.699152\n",
            "[442]  dy_i = 82.70 * x + 44449.76     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.698801\n",
            "[443]  dy_i = 82.70 * x + 44449.76     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.698467\n",
            "[444]  dy_i = 82.70 * x + 44449.77     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.698151\n",
            "[445]  dy_i = 82.70 * x + 44449.77     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.697851\n",
            "[446]  dy_i = 82.70 * x + 44449.78     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.697566\n",
            "[447]  dy_i = 82.70 * x + 44449.78     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.697295\n",
            "[448]  dy_i = 82.70 * x + 44449.79     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.697039\n",
            "[449]  dy_i = 82.70 * x + 44449.79     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.696795\n",
            "[450]  dy_i = 82.70 * x + 44449.80     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.696564\n",
            "[451]  dy_i = 82.70 * x + 44449.80     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.696344\n",
            "[452]  dy_i = 82.70 * x + 44449.81     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.696136\n",
            "[453]  dy_i = 82.70 * x + 44449.81     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.695937\n",
            "[454]  dy_i = 82.70 * x + 44449.81     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.695750\n",
            "[455]  dy_i = 82.70 * x + 44449.82     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.695571\n",
            "[456]  dy_i = 82.70 * x + 44449.82     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.695402\n",
            "[457]  dy_i = 82.70 * x + 44449.83     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.695242\n",
            "[458]  dy_i = 82.70 * x + 44449.83     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.695089\n",
            "[459]  dy_i = 82.70 * x + 44449.83     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.694945\n",
            "[460]  dy_i = 82.70 * x + 44449.84     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.694807\n",
            "[461]  dy_i = 82.70 * x + 44449.84     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.694676\n",
            "[462]  dy_i = 82.70 * x + 44449.84     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.694553\n",
            "[463]  dy_i = 82.70 * x + 44449.85     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.694435\n",
            "[464]  dy_i = 82.70 * x + 44449.85     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.694324\n",
            "[465]  dy_i = 82.70 * x + 44449.85     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.694217\n",
            "[466]  dy_i = 82.70 * x + 44449.86     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.694117\n",
            "[467]  dy_i = 82.70 * x + 44449.86     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.694021\n",
            "[468]  dy_i = 82.70 * x + 44449.86     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.693931\n",
            "[469]  dy_i = 82.70 * x + 44449.86     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.693845\n",
            "[470]  dy_i = 82.70 * x + 44449.87     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.693763\n",
            "[471]  dy_i = 82.70 * x + 44449.87     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.693686\n",
            "[472]  dy_i = 82.70 * x + 44449.87     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.693612\n",
            "[473]  dy_i = 82.70 * x + 44449.88     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.693542\n",
            "[474]  dy_i = 82.70 * x + 44449.88     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.693476\n",
            "[475]  dy_i = 82.70 * x + 44449.88     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.693413\n",
            "[476]  dy_i = 82.70 * x + 44449.88     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.693353\n",
            "[477]  dy_i = 82.70 * x + 44449.88     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.693296\n",
            "[478]  dy_i = 82.70 * x + 44449.89     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.693242\n",
            "[479]  dy_i = 82.70 * x + 44449.89     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.693192\n",
            "[480]  dy_i = 82.70 * x + 44449.89     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.693143\n",
            "[481]  dy_i = 82.70 * x + 44449.89     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.693097\n",
            "[482]  dy_i = 82.70 * x + 44449.89     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.693053\n",
            "[483]  dy_i = 82.70 * x + 44449.90     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.693012\n",
            "[484]  dy_i = 82.70 * x + 44449.90     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.692972\n",
            "[485]  dy_i = 82.70 * x + 44449.90     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.692935\n",
            "[486]  dy_i = 82.70 * x + 44449.90     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.692899\n",
            "[487]  dy_i = 82.70 * x + 44449.90     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.692866\n",
            "[488]  dy_i = 82.70 * x + 44449.91     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.692833\n",
            "[489]  dy_i = 82.70 * x + 44449.91     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.692803\n",
            "[490]  dy_i = 82.70 * x + 44449.91     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.692775\n",
            "[491]  dy_i = 82.70 * x + 44449.91     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.692747\n",
            "[492]  dy_i = 82.70 * x + 44449.91     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.692722\n",
            "[493]  dy_i = 82.70 * x + 44449.91     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.692697\n",
            "[494]  dy_i = 82.70 * x + 44449.91     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.692673\n",
            "[495]  dy_i = 82.70 * x + 44449.92     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.692651\n",
            "[496]  dy_i = 82.70 * x + 44449.92     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.692630\n",
            "[497]  dy_i = 82.70 * x + 44449.92     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.692610\n",
            "[498]  dy_i = 82.70 * x + 44449.92     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.692591\n",
            "[499]  dy_i = 82.70 * x + 44449.92     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.692573\n",
            "[500]  dy_i = 82.70 * x + 44449.92     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.692555\n",
            "[501]  dy_i = 82.70 * x + 44449.92     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.692540\n",
            "[502]  dy_i = 82.70 * x + 44449.92     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.692524\n",
            "[503]  dy_i = 82.70 * x + 44449.93     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.692510\n",
            "[504]  dy_i = 82.70 * x + 44449.93     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.692496\n",
            "[505]  dy_i = 82.70 * x + 44449.93     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.692482\n",
            "[506]  dy_i = 82.70 * x + 44449.93     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.692470\n",
            "[507]  dy_i = 82.70 * x + 44449.93     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.692458\n",
            "[508]  dy_i = 82.70 * x + 44449.93     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.692447\n",
            "[509]  dy_i = 82.70 * x + 44449.93     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.692436\n",
            "[510]  dy_i = 82.70 * x + 44449.93     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.692426\n",
            "[511]  dy_i = 82.70 * x + 44449.93     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.692416\n",
            "[512]  dy_i = 82.70 * x + 44449.94     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.692407\n",
            "[513]  dy_i = 82.70 * x + 44449.94     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.692398\n",
            "[514]  dy_i = 82.70 * x + 44449.94     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.692390\n",
            "[515]  dy_i = 82.70 * x + 44449.94     previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.692382\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "   # close/delete previous plots\n",
        "   plt.close('all')\n",
        "\n",
        "   # create a 1 by 2 plot grid\n",
        "   fig,ax = plt.subplots(1,2,figsize=(18,6),dpi=80)\n",
        "   # lot our usual output\n",
        "   plot_data(data_x,data_y,m,b,ax[0])\n",
        "\n",
        "   # here we also plot the calculated linear fit for comparison\n",
        "   line_x = np.arange(data_x.min(),data_x.max())\n",
        "   line_y = line_x * m_calc + b_calc\n",
        "   ax[0].plot(line_x,line_y,'b-',label='calculated')\n",
        "   # add a legend to the plot and x/y labels\n",
        "   ax[0].legend()\n",
        "   ax[0].set_xlabel('square footage')\n",
        "   ax[0].set_ylabel('sale price')\n",
        "\n",
        "   # plot the loss\n",
        "   loss_x = np.arange(0,len(loss_history))\n",
        "   loss_y = np.asarray(loss_history)\n",
        "   ax[1].plot(loss_x,loss_y, 'o-')\n",
        "   ax[1].set_yscale('log')\n",
        "   ax[1].set_xlabel('loop step')\n",
        "   ax[1].set_ylabel('loss')\n",
        "   plt.show()\n",
        "   # gives us time to see the plot\n",
        "   time.sleep(2.5)\n",
        "   # clears the plot when the next plot is ready to show.\n",
        "   ipydis.clear_output(wait=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "X6SD44AWH6M7",
        "outputId": "6620ca85-3a2b-4a6a-8726-7b5feedce2ff"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(batch_size, epochs=30, learning_rate_m = 1e-7, learning_rate_b = 1e-1):\n",
        "    loss_history = []\n",
        "    num_batches = len(data)//batch_size\n",
        "    loop_N = epochs*num_batches\n",
        "    m = 5.\n",
        "    b = 1000.\n",
        "    for i in range(loop_N):\n",
        "        data_batch = data.sample(batch_size)\n",
        "        data_x = data_batch['GrLivArea'].to_numpy()\n",
        "        data_y = data_batch['SalePrice'].to_numpy()\n",
        "        # update our slope and intercept based on the current values\n",
        "        m = updated_m(data_x,data_y,m,b,learning_rate_m)\n",
        "        b = updated_b(data_x,data_y,m,b,learning_rate_b)\n",
        "\n",
        "        # calculate the loss value\n",
        "        loss_value = np.mean(loss(data_x,data_y,m,b))\n",
        "\n",
        "        # keep a history of our loss values\n",
        "        loss_history.append(loss_value)\n",
        "    #loss_last_epoch = np.sum(loss_history[-num_batches:]*batch_size)/len(data)\n",
        "    return m, b, np.mean(loss(x,y,m,b))"
      ],
      "metadata": {
        "id": "N70moQZCH9eg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I separated the plot above as it was taking exceendingly long to run plotting every step.\n",
        "I had initially also set up the above loop similar to the solution but ran into issues."
      ],
      "metadata": {
        "id": "otBjZ4X2H8Kf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('previously calculated: y_i = %.2f * x + %.2f    loss: %f\\n=======================================' % (m_calc,b_calc,loss_value))\n",
        "\n",
        "\n",
        "for bs in 64, 128, 256, 512:\n",
        "    m, b, l = train(bs, epochs=30)\n",
        "    print(f\"batch size: {bs}, m={m:.4f}, b={b:.4f}, loss={l:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpViWAi0H_1P",
        "outputId": "7d7b722b-8c1a-4573-8618-65eeab824494"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "previously calculated: y_i = 87.69 * x + 34754.08    loss: 1664946654.692382\n",
            "=======================================\n",
            "batch size: 64, m=86.3069, b=34449.7871, loss=1483363645.7197\n",
            "batch size: 128, m=86.2077, b=35246.2951, loss=1480918577.2197\n",
            "batch size: 256, m=89.2613, b=33519.8967, loss=1479423371.8196\n",
            "batch size: 512, m=88.5625, b=33273.7909, loss=1478053756.5454\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in 1, 2, 4, 8:\n",
        "    bs, lrm, lrb = np.array([64, 1e-7, 1e-1])*i\n",
        "    bs = int(bs)\n",
        "    m, b, l = train(int(bs), epochs=30, learning_rate_m = lrm, learning_rate_b = lrb)\n",
        "    print(f\"batch size: {bs}, m={m:.4f}, b={b:.4f}, loss={l:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SY9H70dHIBQ7",
        "outputId": "c88d69e6-5b47-482e-9743-47987b1ccad4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch size: 64, m=91.8314, b=29403.0859, loss=1482729400.7614\n",
            "batch size: 128, m=90.1477, b=32971.0142, loss=1482265299.1842\n",
            "batch size: 256, m=84.6369, b=37116.1407, loss=1484079212.9763\n",
            "batch size: 512, m=55516.8812, b=75418639.1614, loss=24383560007869756.0000\n"
          ]
        }
      ]
    }
  ]
}